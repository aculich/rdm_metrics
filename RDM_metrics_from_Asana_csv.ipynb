{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOUT THIS SCRIPT\n",
    "\n",
    "This script takes a csv file exported from the Consultations project in the Research IT Operations Asana: https://app.asana.com/0/531982708588662/list\n",
    "\n",
    "The script manipulates each row of the spreadsheet as a list. It uses list notation to refer to each column -- or what had been a column in the spreadsheet. For convenience, here are the list indices and headers associated with each column: \n",
    "\n",
    "| Index | Column header |\n",
    "| ------| ------------- |\n",
    "| [0]   | Task ID |\n",
    "| [1]   | Created At |\n",
    "| [2]   | Completed At |\n",
    "| [3]   | Last Modified |\n",
    "| [4]   | Name |\n",
    "| [5]   | Assignee |\n",
    "| [6]   | Assignee Email |\n",
    "| [7]   | Start Date |\n",
    "| [8]   | Due Date |\n",
    "| [9]   | Tags |\n",
    "| [10]  | Notes |\n",
    "| [11]  | Projects |\n",
    "| [12]  | Parent Task |\n",
    "| [13]  | Researcher |\n",
    "| [14]  | Position |\n",
    "| [15]  | PI/Lab |\n",
    "| [16]  | Department / ORU |\n",
    "| [17]  | RIT Service Area |\n",
    "| [18]  | RIT Service Area 2 |\n",
    "| [19]  | RIT Service Area 3 |\n",
    "| [20]  | Source (referrer) |\n",
    "| [21]  | Hand-off and/or referral |\n",
    "| [22]  | Complexity |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA INPUT CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .csv file containing the data is now generated from the Consultations project in Asana, \n",
    "then filtered for date and the tag 'RDM'.\n",
    "\n",
    "These are the parameters (arguments) that must be provided to the script:\n",
    "1. The filepath that points to the .csv file containing our data (which is now being generated from the the Consultations project in Asana).\n",
    "2. The filename of the .csv file.\n",
    "3. The 'report_period_descriptor' will be the text included in the first line of the report created by the script.\n",
    "4. The 'report_start' is the earliest consultation start date of the period covered by the report.\n",
    "5. The 'report_end' is the latest consultation start date of the period covered by the report\n",
    "\n",
    "You can load these from a file if you wish. The file should be a .py file that contains exactly the information shown below in lines 2 through 7. Place the file in the same folder as this Jupyter Notebook file, or provide the path to it in the cell magic command '%load.' (Remove the '#' before '%load' to run the command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Metrics_args_Asana/RDM_metrics_Asana_FY2018_Q3.py\n",
    "# These are the arguments provided to the script\n",
    "filepath = '/Users/rjaffe/Documents/RDM/RDM_Metrics/MetricsData/data-from-asana/June2018-Metrics/'\n",
    "filename = 'Consultations_20180626-1706PT.csv'\n",
    "report_period_descriptor = 'the period from January 1, 2018 through March 31, 2018'\n",
    "report_start = '2018-01-01'\n",
    "report_end = '2018-03-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICTIONARY CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script utilizes dictionaries to store values for counting and to aggregate (\"roll up\"\") individual values \n",
    "under parent values. There are dictionaries for:\n",
    "1. The consultant involved in the consultation\n",
    "2. The department or ORU of the researcher/client\n",
    "3. The position or role of the researcher/client\n",
    "4. The category (RDM service area or lifecycle stage)\n",
    "5. The source of the consultation (or 'referral in'), rolled up to the organizational unit of the individual\n",
    "6. The referral (out), i.e., the person to whom the case was referred, rolled up to their organizational unit\n",
    "7. The complexity of the case\n",
    "8. The parent school, college or division of the researcher's/client's department or unit\n",
    "9. The College of Letters & Science as a whole (includes four divisions).\n",
    "\n",
    "We also use two other dictionaries to hold text values that vary by column:\n",
    "1. The labels used in our output for empty values\n",
    "2. The headings used in our output.\n",
    "\n",
    "Before we load the data file, we must initialize and configure several variables and dictionaries. The configuation files are kept in a directory called Metrics_config_files. There are two dictionaries at this point, one for referral data and one for organization data. We load those files using the cell magic command '%load.' (The file can be located in the same folder as the notebook file itself, or, as we have done, in a folder at the path provided in the %load command.) \n",
    "\n",
    "As new values are added to Asana, they should be added to the second value list within the correct dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must set variables and initialize our dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Positional elements (columns) with the following indices -- and only those elements, at present --\n",
    "# will be gathered and counted using a dictionary\n",
    "# THE POSITIONAL ELEMENTS ASSIGNED HAVE CHANGED.\n",
    "# IDENTIFYING CONSULTANTS WILL BE DONE MUCH DIFFERENTLY, TOO, I SUSPECT.\n",
    "dictable_cols = [5, 16, 14, 17, 18, 19, 20, 21, 22] #Data from Asana csv\n",
    "\n",
    "# In this version, we bring the \"dictable columns\" into dictionaries called:\n",
    "# • ccounter (consultants) \n",
    "# • dcounter (departments/ORUs)\n",
    "# • pcounter (position)\n",
    "# • cacounter (category, now known as service area)\n",
    "# • scounter (source)\n",
    "# • rcounter (referrals out) and \n",
    "# • cocounter (complexity).\n",
    "\n",
    "# Next we do modifications -- rolling up departmental values to their school, college or organizational parent; \n",
    "# L&S is first rolled up to its divisions, then aggregated as a college -- and store in new dictionaries: \n",
    "# • pacounter for values rolled-up by parent\n",
    "# • lscounter for Letters & Science divisions rolled up into a single total\n",
    "\n",
    "#Initialize dictionaries that we'll use later\n",
    "ccounter, dcounter, pcounter, cacounter, scounter, rcounter, cocounter, \\\n",
    "pacounter, lscounter = {},{},{},{},{},{},{},{},{}\n",
    "\n",
    "# Initialize lists of labels and headings\n",
    "labels = ['Unassigned', 'Unknown department', 'Unknown status', 'Unspecified',  'None or Unspecified', 'None or Unspecified', 'Unspecified', 'No hand-off or not specified',\n",
    "          'Unspecified',]\n",
    "\n",
    "orig_headings = ['Consultants, number of consults', 'Departments Served, number of engagements',\n",
    "            'Researcher Status, number of researchers', 'RIT Service Area', 'RIT Service Area', 'RIT Service Area',\n",
    "            'Referrals In', 'Referrals Out', 'Consultation Complexity']\n",
    "mod_headings = ['School, College or Office', 'School, College or Office, with L&S combined'] # for copied values\n",
    "all_headings = ['Consultants, number of consults', 'Departments Served, number of engagements',\n",
    "            'Researcher Status, number of researchers', 'RIT Service Area (all 3 fields)', 'Referrals In', 'Referrals Out',\n",
    "            'Consultation Complexity', 'School, College or Office', 'School, College or Office, with L&S combined']\n",
    "\n",
    "# List of dictionaries with modified values\n",
    "mod_dicts = [pacounter, lscounter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the dictionary that aggregrates Source (referrals in) and Hand-offs and Referrals (out) values. . Uncomment the first line and load the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load Metrics_config_files/config_ref_rollups_20180627.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the dictionary that aggregrates Organization values. Uncomment the first line and load the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Metrics_config_files/config_org_rollups_20180627.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS TO USE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Couldn't get this to work!\n",
    "# import itertools\n",
    "# def remove_header_row(rows):\n",
    "#     #first header value is 'Task ID'; remove that row\n",
    "#     rows = itertools.filterfalse(lambda row: row[0] == 'Task ID', rows)\n",
    "#     return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ, FILTER AND CLEAN THE DATA\n",
    "\n",
    "With the dictionaries in place, the action begins. \n",
    "\n",
    "In the next cell, we read the .csv file and filter out all but the rows we want to keep: tasks with the tag \"RDM\" between the start and end dates of the report. At the same time, we gather information from subtasks (parent task name and subtask assignee) -- but we don't want to keep those rows because we don't want to count the subtasks as separate consultations. \n",
    "\n",
    "In subsequent cells, we prepare the data for counting and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO - Catch and handle missing arguments or errors in the arguments\n",
    "\n",
    "# Convert report_start and report_end arguments to datetime format\n",
    "reportstart = datetime.strptime(report_start, '%Y-%m-%d')\n",
    "reportend = datetime.strptime(report_end, '%Y-%m-%d')\n",
    "\n",
    "# Initialize lists and dictionary that will be used to gather parent task name and subtask assignee values \n",
    "# from subtasks and add these to the list of task assignees \n",
    "parenttasks = [] # parent tasks list\n",
    "assignees = []  # co-assignees list\n",
    "#coassignees = {}  # dictionary of parent tasks and co-assignees names\n",
    "\n",
    "myrows = []   # this will hold the values from each row that we keep, each row stored as a list within this list\n",
    "\n",
    "# Read data into a list of lists, keeping only RDM consultation tasks between report start and end date\n",
    "\n",
    "with open(filepath + filename) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    next(reader) # skip header row  -- TODO: Save header row for writing to output file\n",
    "    rows = [r for r in reader]\n",
    "    for row in rows:\n",
    "        # Filter Asana csv to include only consultations during the desired period that have the tag 'RDM'.\n",
    "        \n",
    "        # Convert Created At values (second column) to datetime format and \\\n",
    "        # compare against report-start and report-end arguments. Skip if start date is not in report period range\n",
    "        # First, replace slashes with dashes\n",
    "        stDate = row[1].replace(\"/\", \"-\")\n",
    "        startdate = datetime.strptime(stDate, '%Y-%m-%d')\n",
    "        if not reportstart <= startdate <= reportend: continue\n",
    "            \n",
    "        # All RDM consultations have been tagged 'RDM'. \n",
    "        # Remove rows in which tag values -- row[9] -- do not include the 'RDM' tag\n",
    "        # First, split tag values into a list (tags values are separated by a comma)\n",
    "        row[9] = row[9].split(',')\n",
    "\n",
    "        if not 'RDM' in row[9]: continue\n",
    "                \n",
    "        # We create subtasks in Asana to manage the consultation work, and sometimes assign the subtask to \n",
    "        # another consultant. We want to track the participation of the additional consultant(s), but not count\n",
    "        # the subtask as a separate consultation.\n",
    "        \n",
    "        # To do this, we need to find those rows that are subtasks and copy the parent task name and \n",
    "        # the assignee name into temporary data structures, but not add the row to the list of rows. \n",
    "        # Eventually, the assignees will be added to the Assignee field (row[5]) \n",
    "        # of the parent task. \n",
    "        \n",
    "        # (Our plan was to identify co-consultants in Asana by assigning that co-consultant a sub-task whose\n",
    "        # name begins \"CO-CONSULT\". Now we're thinking of adding a custom 'Co-consultee' field to track this.\n",
    "        # Still, we want to note the network of all people working on consultations.)\n",
    "          \n",
    "        if row[12] != '':   #if this row has a parent task name, i.e., if this is a subtask\n",
    "            # if row[4] startswith 'CO_CONSULT':   # Leave this for now\n",
    "            parenttasks.append(row[12])\n",
    "            assignees.append(row[5])\n",
    "            continue\n",
    "            \n",
    "        myrows.append(row)\n",
    "        \n",
    "#print(myrows)  #debug only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need to add subtask assignees to the list of assignees of the parent task.\n",
    "# To do that, we'll create a coassignees dictionary with key = parent task name and value = assignee name.\n",
    "\n",
    "# Note that there can be multiple subtasks per parent task, and, though unlikely,\n",
    "# two or more parent tasks with the same name. \n",
    "# We have to check for existing keys when creating the dictionary so we don't overwrite existing values       \n",
    "\n",
    "coassignees = {}  # dictionary of parent tasks and co-assignees names\n",
    "\n",
    "avals = []    # initialize temporary list of assignee values\n",
    "for p, a in zip(parenttasks, assignees):\n",
    "    if p in coassignees:   # If key already exists... \n",
    "        avals.append(coassignees[p])   # add existing value of that key to temporary list\n",
    "        avals.append(a)   # append new value to existing \n",
    "        a = avals  # re-assign to variable\n",
    "    coassignees[p] = a  # assign the new value(s) to the key\n",
    "        \n",
    "# print(coassignees)  # For debugging purposes\n",
    "# for k, v in coassignees.items():    # For debugging purposes - alternate view\n",
    "#    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we've isolated the Asana tasks (rows in the csv file) that we want to count, \n",
    "# iterate through the rows and prepare them for counting. We need to:\n",
    "# • replace empty values with appropriate labels; \n",
    "# • split multiple values in the columns that we will count; \n",
    "# • add subtask assignees to parent tasks; and finally \n",
    "# • make sure that the values we will count are elements in a list. (If they are strings, the Counter function\n",
    "# will iterate over the string and count the occurences of each letter, rather than of the name.)\n",
    "\n",
    "for row in myrows:\n",
    "    \n",
    "    # REPLACE EMPTY VALUES WITH THE APPROPRIATE LABELS\n",
    "    \n",
    "    # For Consultant(s), Department/ORU, Patron status, RIT Service Area (aka Category), \n",
    "    # Source (aka referral in), Hand-off or referral (aka referral out), Consultation complexity: \n",
    "    # replace empty values with appropriate label.\n",
    "        \n",
    "    # for n, label in zip(config_20171104.dictable_cols, config_20171104.labels):  ## USE THIS IN PYCHARM\n",
    "    for n, label in zip(dictable_cols, labels):\n",
    "\n",
    "        # Fill in empty cells with appropriate label\n",
    "        if row[n] == '':\n",
    "            row[n] = label\n",
    "\n",
    "            \n",
    "    # SPLIT MULTIPLE VALUES IN COLUMNS THAT WE WILL COUNT\n",
    "        \n",
    "    for n in [16, 20, 21]:   # Dept/ORU, Source and Hand-offs... may have multiple values separated by '; '\n",
    "        if type(row[n]) == str:\n",
    "            row[n] = row[n].split('; ')\n",
    "        \n",
    "    # ADD SUBTASK ASSIGNEES TO PARENT TASKS\n",
    "        \n",
    "    if row[4] in coassignees.keys():  # If this task is the parent of one of the subtasks we encountered earlier...\n",
    "        \n",
    "        subassigns = []  \n",
    "        uniqueassigns = []\n",
    "        assigns = []\n",
    "        \n",
    "        if type(coassignees[row[4]]) == list:  # multiple subtasks for same task\n",
    "            for c in coassignees[row[4]]:\n",
    "                subassigns.append(c)          # add each task owner to a list\n",
    "        elif type(coassignees[row[4]]) == str:   # only one subtask, only one assignee, therefore a string value\n",
    "            subassigns.append(coassignees[row[4]]) # make a list of the single subtask assignee\n",
    "            \n",
    "        for s in subassigns:\n",
    "            if s == '':    # if no one assigned, skip\n",
    "                continue\n",
    "            elif s in uniqueassigns:  # if a subtask of the same parent task is already assigned to a person, skip\n",
    "                continue\n",
    "            else:   # capture this name\n",
    "                uniqueassigns.append(s)\n",
    "        \n",
    "        assigns.append(row[5])  # start a list beginning with task assignee, add subtask assignee(s) if unique\n",
    "        \n",
    "        for u in uniqueassigns:\n",
    "            if u == '':    # shouldn't be possible\n",
    "                continue\n",
    "            elif u in assigns:\n",
    "                continue\n",
    "            else:\n",
    "                assigns.append(u)\n",
    "            \n",
    "        row[5] = assigns\n",
    "        \n",
    "    else:     # Convert string to list\n",
    "        consultant = []\n",
    "        consultant.append(row[5])\n",
    "        row[5] = consultant\n",
    "    \n",
    "    # ASSURE CELL VALUES ARE ELEMENTS IN A LIST SO THAT THE COUNTER FUNCTION DOESN'T ITERATE OVER STRINGS \n",
    "\n",
    "    for n in [14, 16, 17, 18, 19, 22]:\n",
    "        txt = []\n",
    "        if type(row[n]) == list:\n",
    "            for r in row[n]:\n",
    "                txt.append(r)\n",
    "        elif type(row[n]) == str:\n",
    "            txt.append(row[n])    \n",
    "        row[n] = txt\n",
    "        \n",
    "# print(myrows)  # debug only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGGREGATE DATA\n",
    "\n",
    "Now we do our first aggregation: we roll-up the individual sources of referrals (in) and the individuals to whom we referred (out) researchers into their unit or division affiliation.  \n",
    "\n",
    "Eventually, we will aggregate/roll-up a series of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AGGREGATE (ROLL-UP) VALUES \n",
    "myrows_aggregated = myrows\n",
    "\n",
    "for row in myrows_aggregated:\n",
    "    \n",
    "    # Replace individual names with the corresponding org name in Source (aka Referral In) and\n",
    "    # Hand-off or referral (aka Referral Out) fields\n",
    "    # (positional elements [20] and [21])\n",
    "    for n in [20, 21]:\n",
    "        ref_x = []\n",
    "        if type(row[n]) == list:\n",
    "            for r in row[n]:\n",
    "                ref_x.append(r)\n",
    "        elif type(row[n]) == str:\n",
    "            ref_x.append(row[n])\n",
    "        row[n] = []  # Empty cell to ready it for being re-filled\n",
    "        for term in ref_x:\n",
    "            #for key in config_20171104.ref_rollups.keys():    ## USE THIS IN PYCHARM\n",
    "            for key in ref_rollups.keys():\n",
    "                #if term in config_20171104.ref_rollups[key][1]:   ## USE THIS IN PYCHARM\n",
    "                if term in ref_rollups[key][1]: \n",
    "                    #term = config_20171104.ref_rollups[key][0]    ## USE THIS IN PYCHARM\n",
    "                    term = ref_rollups[key][0]\n",
    "        row[n].append(term)\n",
    "                    \n",
    "# print(myrows_aggregated)  # Debug only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE TO FILE\n",
    "\n",
    "Write our cleaned and partially aggregated data set to a file for safe keeping and other uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a filename with a simple timestamp so we don't overwrite file each time we write.\n",
    "path = 'Metrics_output/'\n",
    "basename = 'rdm_filteredtasks_aggregatedreferrals_'\n",
    "datestr = str(datetime.today())\n",
    "datestr = datestr[:-7]   # Remove microseconds\n",
    "datestr = datestr.replace(' ', 'T')  # Replace space with 'T' so filename doesn't cause problems elsewhere\n",
    "datestr = datestr.replace(':','-')  # The colons in the timestamp may cause problems, so swap them out, too\n",
    "fileoutname = path + basename + datestr + '.csv'\n",
    "\n",
    "with open(fileoutname, 'w', newline='') as csvfile:\n",
    "    rdmwriter = csv.writer(csvfile)\n",
    "    rdmwriter.writerows(myrows_aggregated)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of consultations (number of rows gathered above) and determine how many have been resolved successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ***** COUNT THE DATA *****\n",
    "# Each row (list) represents a consulting engagement\n",
    "print('\\nI %s, RDM Consulting provided %d consultations.' % (report_period_descriptor, (len(myrows))))\n",
    "\n",
    "# # Count how many engagements are resolved successfully\n",
    "# #TODO: FIGURE OUT HOW TO MEASURE THIS\n",
    "# yesrows = []\n",
    "\n",
    "# for r in myrows_aggregated:\n",
    "#     r15 = r[15]\n",
    "#     if 'Resolved' in r15:\n",
    "#         yesrows.append(r)\n",
    "\n",
    "# #print('We reached a successful resolution in %d of those engagements.' % len(yesrows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we count and store the unique values in several of the erstwhile columns and print the totals to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gather and count (subtotal) the values for consultant(s), department/oru, researcher status, RIT Service Area \n",
    "# (formerly category), source (referrals in), hand-off or referral (referrals out) and consultation complexity.\n",
    "\n",
    "#for i, n in enumerate(config_20171104.dictable_cols):   ## USE THIS IN PYCHARM\n",
    "for i, n in enumerate(dictable_cols):  # the i identifies heading to use when printing results to screen (below)\n",
    "    counter = Counter()\n",
    "    for row in myrows_aggregated:\n",
    "        for z in row[n]:\n",
    "            counter[z] += 1\n",
    "        if n == 5:\n",
    "            ccounter.update(counter.most_common())\n",
    "        elif n == 16:\n",
    "            dcounter.update(counter.most_common())     \n",
    "        elif n == 14:\n",
    "            pcounter.update(counter.most_common())\n",
    "        elif (n == 17) or (n == 18) or (n == 19):   # Add together the three RIT Service Area fields\n",
    "            cacounter.update(counter.most_common())\n",
    "        elif n == 20:\n",
    "            scounter.update(counter.most_common())\n",
    "        elif n == 21:\n",
    "            rcounter.update(counter.most_common())\n",
    "        else:\n",
    "            cocounter.update(counter.most_common())\n",
    "    \n",
    "    # Print results to screen\n",
    "    #print('\\n' + config_20171104.orig_headings[j] + ':')  # Use this in Pycharm or command-line invocation\n",
    "    print('\\n' + orig_headings[i] + ':')\n",
    "    for (k, v) in counter.most_common():\n",
    "        print(k + ': ' + str(v))\n",
    "    \n",
    "# Uncomment to view data structures and to debug        \n",
    "# print('\\n')\n",
    "# print(ccounter)\n",
    "# print('\\n')\n",
    "# print(dcounter)\n",
    "# print ('\\n')\n",
    "# print(pcounter)\n",
    "# print('\\n')\n",
    "# print(cacounter)\n",
    "# print('\\n')\n",
    "# print(scounter)\n",
    "# print('\\n')\n",
    "# print(rcounter)\n",
    "# print('\\n')\n",
    "# print(cocounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, modify the values and write to new dictionaries: roll-up department/ORU key/value pairs into schools, colleges and divisions, first with the divisions of the College of Letters & Science separated and then with the divisions all counted within the College. [TODO: Do the same for the divisions of the College of Engineering?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate (\"roll-up\") granular Department value into corresponding parent organization value\n",
    "\n",
    "for k, v in dcounter.items():\n",
    "    #for key in config_20171104.org_rollups.keys():    # Use this in Pycharm or command-line invocation\n",
    "    for key in org_rollups.keys():\n",
    "        #if k in config_20171104.org_rollups[key][1]:   # Use this in Pycharm or command-line invocation\n",
    "        if k in org_rollups[key][1]:         # No else to this if: org_rollup dict updated to include all keys (Depts)\n",
    "            #k = config_20171104.org_rollups[key][0]    # Use this in Pycharm or command-line invocation\n",
    "            k = org_rollups[key][0]\n",
    "            if k in pacounter.keys():\n",
    "                pacounter[k] = (pacounter[k] + v)\n",
    "            else:\n",
    "                pacounter[k] = v\n",
    "\n",
    "# Additionally, roll-up all Letters & Science in one L&S tally\n",
    "\n",
    "for k, v in pacounter.items():\n",
    "    #for key in config_20171104.ls_rollup.keys():    # Use this in Pycharm or command-line invocation\n",
    "    for key in ls_rollup.keys():\n",
    "        #if k in config_20171104.ls_rollup[key][1]:   # Use this in Pycharm or command-line invocation\n",
    "        if k in ls_rollup[key][1]:\n",
    "            #k = config_20171104.ls_rollups[key][0]    # Use this in Pycharm or command-line invocation\n",
    "            k = ls_rollup[key][0]\n",
    "            if k in lscounter.keys():\n",
    "                lscounter[k] = (lscounter[k] + v)  # L&S-All key added previously; add value to existing value\n",
    "            else:\n",
    "                lscounter[k] = v  # No other item rolled-up yet; add L&S-All key, assign value \n",
    "        else:\n",
    "            lscounter[k] = v  # key not in set of keys to be rolled up, guaranteed to be unique within this dict\n",
    "\n",
    "\n",
    "# # Print results to screen\n",
    "#for h, d in zip(config_20171104.mod_headings, config_20171104.mod_dicts):  # Use this in Pycharm or command-line invocation\n",
    "for h, d in zip(mod_headings, mod_dicts):\n",
    "    print('\\n' + h + ':')\n",
    "    for (k, v) in d.items():\n",
    "        print(k + ': ' + str(v))     \n",
    "\n",
    "# Uncomment to view data and to debug        \n",
    "# print('\\n')\n",
    "# print(pacounter)\n",
    "# print('\\n')\n",
    "# print(lscounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numbers in hand, we prepare data structures to use in visualization and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For graphing and other analysis, we need to create portable, persistent data structures.\n",
    "# We will do this by creating a list of lists, each list comprising the key/value pairs from one dictionary. \n",
    "# Then we will sort each of those lists and add each to a list of sorted lists\n",
    "\n",
    "# Initialize the lists - unsorted and sorted (the dicts have been created above). \n",
    "# Name each list for the dictionary it will be drawn from.\n",
    "ccount, dcount, pcount, cacount, scount, rcount, cocount, pacount, lscount = [[],[],[],[],[],[],[],[],[]]\n",
    "sccount, sdcount, spcount, scacount, sscount, srcount, scocount, spacount, slscount = [[],[],[],[],[],[],[],[],[]]  # 's' for sorted\n",
    "\n",
    "# Create containers with the names of our dicts and lists so we can do all the processing in a loop\n",
    "dcts = [ccounter, dcounter, pcounter, cacounter, scounter, rcounter, cocounter, pacounter, lscounter]\n",
    "lsts = [ccount, dcount, pcount, cacount, scount, rcount, cocount, pacount, lscount]\n",
    "srtdlsts = [sccount, sdcount, spcount, scacount, sscount, srcount, scocount, spacount, slscount]\n",
    "\n",
    "# For each dictionary item, append the key/value pair as a tuple to the named list related to the dictionary\n",
    "for d, l, s in zip(dcts, lsts, srtdlsts):\n",
    "    for key in d.keys():\n",
    "        tup = (key, d[key])\n",
    "        l.append(tup)\n",
    "    # Sort each list by the second element in each tuple (the value of the original key/value pair) and add\n",
    "    # the sorted list to list of sorted lists\n",
    "    s.extend(sorted(l, key=lambda x: x[1], reverse=True))  # reverse means descending order\n",
    "    \n",
    "# Uncomment the next lines view data on screen    \n",
    "# for lst in lsts:\n",
    "#     print(lst)\n",
    "#     print('\\n')\n",
    "# for srtdlst in srtdlsts:\n",
    "#     print(srtdlst)\n",
    "#     print('\\n')\n",
    "\n",
    "# Uncomment these print commands to review individual lists by name\n",
    "# print(str(ccount) + '\\n')\n",
    "# print(str(dcount) + '\\n')\n",
    "# print(str(pcount) + '\\n')\n",
    "# print(str(cacount) + '\\n')\n",
    "# print(str(scount) + '\\n')\n",
    "# print(str(rcount) + '\\n')\n",
    "# print(str(cocount) + '\\n')\n",
    "# print(str(pacount) + '\\n')\n",
    "# print(str(lscount) + '\\n')\n",
    "# print(str(sccount) + '\\n')\n",
    "# print(str(sdcount) + '\\n')\n",
    "# print(str(spcount) + '\\n')\n",
    "# print(str(scacount) + '\\n')\n",
    "# print(str(sscount) + '\\n')\n",
    "# print(str(srcount) + '\\n')\n",
    "# print(str(scocount) + '\\n')\n",
    "# print(str(spacount) + '\\n')\n",
    "# print(str(slscount) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we write these to a file? (Of course we can.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create a filename with a simple timestamp so we don't overwrite file each time we write.\n",
    "path = 'Metrics_output/'\n",
    "basename = 'rdm_tabulations_'\n",
    "datestr = str(datetime.today())\n",
    "datestr = datestr[:-7]   # Remove microseconds\n",
    "datestr = datestr.replace(' ', 'T')  # Replace space with 'T' so filename doesn't cause problems elsewhere\n",
    "datestr = datestr.replace(':','-')  # The colons in the timestamp may cause problems, so swap them out, too\n",
    "fileoutname = path + basename + datestr + '.txt'\n",
    "#print(filename) #debug\n",
    "\n",
    "with open(fileoutname, 'w') as f:\n",
    "    \n",
    "    f.write('\\nIn %s, RDM Consulting provided %d consultations.\\n\\n' % (report_period_descriptor, (len(myrows))))\n",
    "    \n",
    "    for lst, hdr in zip(srtdlsts,all_headings):\n",
    "        h = hdr\n",
    "        f.write(h + ':\\n\\n')\n",
    "        for item in lst:\n",
    "            k = item[0]\n",
    "            v = item[1]\n",
    "            f.write(k + ': ' + str(v))\n",
    "            f.write('\\n')\n",
    "        f.write('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot pie charts for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pie charts of each category, where the slices will be ordered and plotted counter-clockwise:\n",
    "\n",
    "for s in srtdlsts:\n",
    "    \n",
    "    labels = []\n",
    "    sizes = []\n",
    "    labelsplusn = []\n",
    "    \n",
    "    for pair in s:\n",
    "        labels.append(pair[0])\n",
    "        sizes.append(pair[1])\n",
    "\n",
    "    #print(labels) #debug\n",
    "    #print(sizes)  #debug\n",
    "    \n",
    "    for label, size in zip(labels, sizes):\n",
    "        labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "        labelsplusn.append(labelplusn)\n",
    "    \n",
    "    #print(labelsplusn)  #debug\n",
    "    \n",
    "    explode = [.1 for _ in range(len(s))]  # one value for each element in len(sortedlist)\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  # originally labels=labels\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    plt.show()\n",
    "    #print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of cells generate each pie chart separately so we can customize them. \n",
    "\n",
    "NOTE: These need to be customized based on the date range: the number of arguments in the statement 'explode = ()'\n",
    "must be equal to the number of items in the sorted list, and that will vary depending upon the range of time covered by the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pie chart of schools, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in spacount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "#print(len(labels))\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "    \n",
    "explode = (.3, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .2, .3, .4, .5,  .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_spacount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of schools with all L&S combined, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in slscount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "#print(len(labels))\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.2, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5,  .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  #originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_slscount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of original department/oru values, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in sdcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (2.1, 1.9, 1.9, 1.8, 1.9, 2.1, 2.3, 2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 3.7, 3.9, 4.3, 4.7, 5.1, 5.5, 10.1, 9.7, 9.5, 9.3, 9.1, 8.9, 8.7, 8.5, 8.3, 8.1, 7.9, 7.7, 7.5, 7.3, 7.1, 6.9, 6.7, 6.5, 6.3, 6.1, 5.9, 5.7, 5.5, 5.3, 5.1, 4.9, 4.7, 4.5, 4.3, 4.1, 3.9, 2.1, 2.3,  2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 3.7, .8, .8, .8, .9, .9, .9, .9, .9, .9, .9, .9, .9, .9, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_sdcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of position of client on campus, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in spcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .2, .3, .4, .5, .6, .7, .8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_spcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of (RDM Lifecycle) category, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in scacount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5, .6, .7, .8, .9, )  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_scacount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of sources (referrals in), where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in sscount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5, .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_sscount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of referrals out, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in srcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_srcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of complexity measures, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in scocount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=40) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_scocount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top five values in each category (or all values, if less than five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lst, hdr in zip(srtdlsts, all_headings):\n",
    "    print('\\n' + 'Top Five: ' + hdr)\n",
    "    for i in range(5):\n",
    "        if i >= len(lst): continue\n",
    "        (k,v) = lst[i]\n",
    "        print(str(i+1) + '. ' + k + ': ' + str(v))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
